"""
Author: J. Brand
Affiliation: Unibas
Aim: Workflow for transcriptome assembly, annotation and assessment
Date: 20. Nov. 2016
Run: snakemake   -s Snakefile
Latest modification:
  - add more flexible input
  - add reporting
  - add checks for gzip
  - integrate gzip of intermediate results
  - add a block to run if fail or succeed
  - add evironment file for bioconda
"""
# import statements
from snakemake.utils import report
from os.path import join
import os
import time


# Uses a yaml file as input
configfile: "config.yaml"

# Preparation------------------------------------------------------------------
TIMESTAMP = time.strftime("%Y%m%d")

# check if the necessary dirs exist and if not creates them
def save_mkdir( dirs ):
	for d in dirs:
		if not os.path.isdir(d):
			os.mkdir(d)
			print("Creating directory: " + d)


dirs = ["logs", "logs/trinity", "logs/transrate",
        "logs/rcorrector", "trinity", "transrate",
        "transrate/summary", "busco", "logs/busco"]
save_mkdir(dirs)

# Globals ---------------------------------------------------------------------

# define global things here

# Full path to a folder that holds all of your FASTQ files.
FASTQ_DIR = config["fastqdir"]

# A Snakemake regular expression matching the forward mate FASTQ files.
# we get a list with the names of all the files in the working directory
SAMPLES, = glob_wildcards(join(FASTQ_DIR, '{sample}_R1.fq'))

# Patterns for the 1st mate and the 2nd mate using the 'sample' wildcard.
PATTERN_R1 = '{sample}_R1.fq'
PATTERN_R2 = '{sample}_R2.fq'

# Rules -----------------------------------------------------------------------



rule all:
    input:
        "report.html"

# This is a template script to run trinity
# Using a JSON file as input will be better
# Sample is a wildcard equivalent to .+
# rule All: # this top rule is here to define the goal of the script
#     input:
#         "{sample}trinotate_annotation_report.xls"
#     log:"snakemake.report.log"

# TODO software version printout and link to report

rule run_rcorrector:
    input:
        forward = join(FASTQ_DIR, PATTERN_R1),
        reverse = join(FASTQ_DIR, PATTERN_R2)
    output:
        FASTQ_DIR + "{sample}_R1.cor.fq",
        FASTQ_DIR + "{sample}_R2.cor.fq"
    log:
    	"logs/rcorrector/{sample}.log"
    params:
        outdir = config["fastqdir"]
    shell:
        """
        ~/perl5/perlbrew/perls/5.16.2t/bin/perl ~/bin/run_rcorrector.pl -k 31 -t 30 \
        -od {params.outdir}  -1 {input.forward}  -2 {input.reverse} &> {log}
        """


rule trim_and_trinity:
    input:
        forward  = FASTQ_DIR + "{sample}_R1.cor.fq",
        reverse  = FASTQ_DIR + "{sample}_R2.cor.fq"
    output:
        assembly = expand("{{sample}}_{T}.Trinity.fasta", T=TIMESTAMP),
        log      = expand("logs/trinity/{{sample}}_{T}.shell.log", T=TIMESTAMP)
    log:
        expand("logs/trinity/{{sample}}_{T}.log", T=TIMESTAMP)
    params:
        adapters =  config["adapters_fasta"],
        outdir   =  config["fastqdir"],
        trinity  =  config["trinity"]
    threads: 28  # threads only works if --cores is set to the actual number of cores when running the snakemake
    # message: expand("Executing with {threads} threads on the following files {sample}.", sample=SAMPLES)
    # We also want a logfile
    # log: expand("logs/{sample}.trinity.log", sample=SAMPLES)
    shell:
        """
        {params.trinity} --seqType fq \
        --trimmomatic --CPU {threads} --max_memory 150G \
        --output 'trinity/'{wildcards.sample}_{TIMESTAMP}'.trinity' \
        --left   {input.forward}  \
        --right  {input.reverse} \
        --normalize_reads  --normalize_max_read_cov 30 \
        --quality_trimming_params 'ILLUMINACLIP:{params.adapters}:2:40:15 LEADING:2 TRAILING:2 MINLEN:25' > ./logs/trinity/{wildcards.sample}_{TIMESTAMP}.shell.log 2> {log} && \
        mv trinity/{wildcards.sample}_{TIMESTAMP}.trinity/Trinity.fasta {output.assembly}
        """

rule run_transrate:
    input:
        assembly =  expand("{{sample}}_{T}.Trinity.fasta", T=TIMESTAMP),
        forward  =  FASTQ_DIR + "{sample}_R1.cor.fq",
        reverse  =  FASTQ_DIR + "{sample}_R2.cor.fq"
    output:
        expand("transrate/{{sample}}_{T}.transrate/{{sample}}_{T}.Trinity/good.{{sample}}_{T}.Trinity.fasta", T=TIMESTAMP),
        expand("transrate/{{sample}}_{T}.transrate/assemblies.csv", T=TIMESTAMP),
        expand("transrate/{{sample}}_{T}.transrate/{{sample}}_{T}.Trinity/contigs.csv", T=TIMESTAMP)
    log:
    	expand("logs/transrate/{{sample}}_{T}.log", T=TIMESTAMP)
    params:
        transDir  =  config["transrateDir"],
        dataDir   =  config["fastqdir"],
        homeDir   =  config["homedir"],
        transrate =  config["transrate"]
    threads: 28
    shell:
        """
        {params.transrate} --assembly {params.homeDir}{input.assembly} \
        --output {params.transDir}{wildcards.sample}_{TIMESTAMP}.transrate \
        --threads {threads} \
        --left {input.forward} \
        --right {input.reverse} > logs/transrate/{wildcards.sample}.transrate.log 2> {log}
        """

rule gather_transrate:
    # move all transrate results to same folder for easier summary later
    # First I used the same wildcard input output names for this rule as I did
    # for the gather busco rule but that somehow caused it not to be plotted in the
    # dag. More of a cosmetic issue.
    input:
        a = expand("transrate/{{sample}}_{T}.transrate/assemblies.csv", T=TIMESTAMP),
        c  = expand("transrate/{{sample}}_{T}.transrate/{{sample}}_{T}.Trinity/contigs.csv", T=TIMESTAMP)
    output:
        a = expand("transrate/summary/{{sample}}_{T}.assemblies.csv", T=TIMESTAMP),
        c = expand("transrate/summary/{{sample}}_{T}.contigs.csv", T=TIMESTAMP)
    shell:
        """
        cp {input.a} {output.a}
        cp {input.c}  {output.c}

        """

        # assembly = "transrate/summary/" + TIMESTAMP + "assemblies.csv"

# Here the assemblies are being summarized and we need to expanda list
rule summarize_transrate_assembly:
    input:
        expand("transrate/summary/{sample}_{T}.assemblies.csv",sample=SAMPLES, T=TIMESTAMP)
    output:
        "transrate/summary/run_" + TIMESTAMP + "_assemblies.csv"
    run:
        assemblies = input
        #generate first line we need in outfile:
        with open(output[0], "w") as outfile:
            with open(assemblies[0], "r") as infile:
                lines = infile.readlines()
                outfile.write(lines[0])

        # now we open the outfile in appending mode to add all the results
        with open(output[0], "a") as outfile:
            for assembly in assemblies:
                with open(assembly, "r") as infile:
                    lines = infile.readlines()
                    outfile.write(lines[1])

# transrate plotting
# TODO change locations of file to something sensible
# ownimgg directory?
rule plot_transrate_contigs:
    input:
        expand("transrate/summary/{{sample}}_{T}.contigs.csv", T=TIMESTAMP)
    output:
        expand("{{sample}}_{T}.png", T=TIMESTAMP)
    script:
        "R/contigs.plot.R"

# rule cat_transrate:
#     input:
#         expand("logs/transrate/{sample}.transrate.log", sample = SAMPLES)
#     output:
#         "trans.sentinel"
#     shell:
#         "touch trans.sentinel"

# add busco rule
rule busco:
    input:
        assembly =   expand("{{sample}}_{T}.Trinity.fasta", T=TIMESTAMP)
    output:
        out      =   expand(config["homedir"] + "busco/run_{{sample}}_{T}.busco/short_summary_{{sample}}_{T}.busco.txt", T=TIMESTAMP)
    params:
        py3      =   config["py3"],
        BUSCO    =   config["BUSCO"],
        BuscoLib =   config["BuscoLib"],
        homedir  =   config["homedir"],
        folder   =   expand("run_{{sample}}_{T}.busco", T=TIMESTAMP)
    threads: 14
    log:
        expand("logs/busco/{{sample}}_{T}.log", T=TIMESTAMP)

    shell:
        # cd {params.outdir}
        """
        {params.py3}  {params.BUSCO} -f \
                -i {params.homedir}{input.assembly} \
                -o {wildcards.sample}_{TIMESTAMP}.busco              \
                -l  {params.BuscoLib}    \
                -m  tran -c {threads} &>> {log} && \
        mv  {params.folder}  busco/

        """


rule busco_on_transrate:
    # run busco on transrate optimized assembly
    input:
        assembly =   expand("transrate/{{sample}}_{T}.transrate/{{sample}}_{T}.Trinity/good.{{sample}}_{T}.Trinity.fasta", T=TIMESTAMP)
    output:
        out      =   config["homedir"] + expand("busco/run_{{sample}}_{T}.good.busco/short_summary_{{sample}}_{T}.good.busco.txt", T=TIMESTAMP)
    params:
        outdir   =   config["homedir"] + "busco/",
        py3      =   config["py3"],
        BUSCO    =   config["BUSCO"],
        BuscoLib =   config["BuscoLib"],
        homedir  =   config["homedir"],
        folder   =   expand("run_{{sample}}_{T}.good.busco", T=TIMESTAMP)
    threads: 14
    log:
        expand("logs/busco/{{sample}}_{T}.good.log", T=TIMESTAMP)

    shell:
        # cd {params.outdir}
        """
        {params.py3}  {params.BUSCO} -f \
                -i {params.homedir}{input.assembly} \
                -o {wildcards.sample}.good.busco              \
                -l  {params.BuscoLib}    \
                -m  tran -c {threads} &>> {log} && \
        mv  {params.folder}  busco/

        """
# TODO rule decision on assembly
rule gather_busco:
    # move all transrate results to same folder for easier summary later
    # we do not need the expand statement here because plot busco will just call this function many times
    input:
        normal   = config["homedir"] + expand("busco/run_{{sample}}_{T}.busco/short_summary_{{sample}}_{T}.busco.txt", T=TIMESTAMP),
        good     = config["homedir"] + expand("busco/run_{{sample}}_{T}.good.busco/short_summary_{{sample}}_{T}.good.busco.txt", T=TIMESTAMP)
    output:
        normal   = expand("busco/summary/short_summary_{{sample}}_{T}.busco.txt", T=TIMESTAMP),
        good     = expand("busco/summary/short_summary_{{sample}}_{T}.good.busco.txt", T=TIMESTAMP)
    shell:
        """
        cp {input.normal} {output.normal}
        cp {input.good}   {output.good}

        """
rule plot_busco:
    input:
        normal   = expand("busco/summary/short_summary_{sample}_{T}.busco.txt", sample=SAMPLES, T=TIMESTAMP),
        good     = expand("busco/summary/short_summary_{sample}_{T}.good.busco.txt", sample=SAMPLES, T=TIMESTAMP)
    output:
        png      = "busco/summary/run_" + TIMESTAMP + "_busco.png",
        R        = "busco/summary/run_" + TIMESTAMP + "_busco.R"
    params:
        py3      = config["py3"],
        BUSCO_p  = config["BUSCO_p"]
    shell:
        """
        {params.py3} {params.BUSCO_p} --working_directory busco/summary && \
        mv busco/summary/busco_figure.png {output.png} && \
        mv busco/summary/busco_figure.R {output.R}
        """

# TODO rename assembly headers
# TODO
# add plotting for BUSCO
# The default plotting does not work and we have to add
# options(bitmapType='cairo')
# at the beginning of the script. -.-
rule versions:
    output:
        log         = "logs/software.versions"
    params:
        trinity     = config["trinity"],
        transrate   = config["transrate"],
        BUSCO       = config["BUSCO"],
        time        = TIMESTAMP
    shell:
        """
        echo "These are the versions of software used for run: {params.time}" &>> {output.log}
        date  &>> {output.log}
        python --version &>> {output.log}
        hmmscan -h | grep -E '^\#\ H' &>> {output.log}
        blastn -h | grep Nucleotide &>> {output.log}
        embossversion &>> {output.log}
        echo "perl version: " &>> {output.log}
        perl -e 'print $];' &>> {output.log}
        {params.BUSCO} --version &>> {output.log}
        echo "transrate version:" {params.transrate} --version &>> {output.log}
        {params.trinity} --version &>> {output.log}
        """
# TODO report file should contain:
# plot of coverage
# busco and transrate stats
# software versions
# timestamp
rule report:
    input:
        busco_png           = "busco/summary/run_" + TIMESTAMP + "_busco.png",
        transrate_summary   = "transrate/summary/run_" + TIMESTAMP + "_assemblies.csv",
        assembly_plot       = expand("{sample}_{T}.png", sample=SAMPLES, T=TIMESTAMP),
        versions            = "logs/software.versions"
    output:
        "report.html"
    run:
        # from snakemake.utils import report
        #with open(input[0]) as trans.logs:
        #    print(trans.logs)
        report("""
        Report on macpipe_trans run
        ===================================


        .. image:: {input.busco_png}


        assembly_plot_
        """, output[0], **input)



# Finishing up --------------------------------------------------------------
onsuccess:
    print("Workflow finished, no error")
onerror:
    print("An error occurred with the snakemake run")
    # here it would be good to include timstamping
    shell("mail -s 'Error in Snakemake run' jeremias.brand@unibas.ch < {log}")

# TODO add separate snakefile for annotation
