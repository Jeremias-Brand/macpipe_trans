"""
Author: J. Brand
Affiliation: Unibas
Aim: Workflow for transcriptome assembly, annotation and assessment
Date: 20. Nov. 2016
Run: snakemake   -s Snakefile

This version is tailored to smaller read numbers and does not use rcorrector.
Here I 
Latest modification:
  - add more flexible input
  - add reporting
  - add checks for gzip
  - integrate gzip of intermediate results
  - add a block to run if fail or succeed
  - add evironment file for bioconda
"""
# import statements
from snakemake.utils import report
from os.path import join
import os
import time


# Uses a yaml file as input
configfile: "config.macpipe.trans.small.yaml"

# Preparation------------------------------------------------------------------
TIMESTAMP = time.strftime("%Y%m%d")


# check if the necessary dirs exist and if not creates them
def save_mkdir( dirs ):
	for d in dirs:
		if not os.path.isdir(d):
			os.mkdir(d)
			print("Creating directory: " + d)


dirs = ["logs", "logs/trinity", "logs/transrate",
        "logs/rcorrector", "trinity", "transrate",
        "transrate/summary", "busco", "logs/busco"]
save_mkdir(dirs)

# Globals ---------------------------------------------------------------------

# define global things here

# Full path to a folder that holds all of your FASTQ files.
FASTQ_DIR = config["fastqdir"]

# A Snakemake regular expression matching the forward mate FASTQ files.
SAMPLES, = glob_wildcards(join(FASTQ_DIR, '{sample}_R1.fq'))

# Patterns for the 1st mate and the 2nd mate using the 'sample' wildcard.
PATTERN_R1 = '{sample}_R1.fq'
PATTERN_R2 = '{sample}_R2.fq'

# Rules -----------------------------------------------------------------------
rule all:
    input:
        "report.html"

rule trim_and_trinity:
    input:
        forward = FASTQ_DIR + "{sample}_R1.fq",
        reverse = FASTQ_DIR + "{sample}_R2.fq"
    output:
        "{sample}_TIMESTAMP.Trinity.fasta",
        "logs/trinity/{sample}_{TIMESTAMP}.shell.log"
    log:
        "logs/trinity/{sample}_{TIMESTAMP}.log"
    params:
        adapters =  config["adapters_fasta"],
        outdir   =  config["fastqdir"],
        trinity  =  config["trinity"],
        leading  =  config["trim_leading"],
        trailing  =  config["trim_trailing"],
        minlength  =  config["trim_minlength"]
    threads: 14  # threads only works if --cores is set to the actual number of cores when running the snakemake
    # message: expand("Executing with {threads} threads on the following files {sample}.", sample=SAMPLES)
    # We also want a logfile
    # log: expand("logs/{sample}.trinity.log", sample=SAMPLES)
    shell:
        """
        {params.trinity} --seqType fq \
        --trimmomatic --CPU {threads} --max_memory 80G \
        --output 'trinity/'{wildcards.sample}'.trinity' \
        --left   {input.forward}  \
        --right  {input.reverse} \
        --normalize_reads  --normalize_max_read_cov 30 \
        --quality_trimming_params 'ILLUMINACLIP:{params.adapters}:2:40:15 LEADING:{params.leading} TRAILING:{params.trailing} MINLEN:{params.minlength}' > ./logs/trinity/{wildcards.sample}_{TIMESTAMP}.shell.log 2> {log} && \
        mv trinity/{wildcards.sample}.trinity/Trinity.fasta {wildcards.sample}_{TIMESTAMP}.Trinity.fasta
        """
# This part here renames the trinity file


rule run_transrate:
    input:
        assembly =  "{sample}_TIMESTAMP.Trinity.fasta",
        forward  =  FASTQ_DIR + "{sample}_R1.fq",
        reverse  =  FASTQ_DIR + "{sample}_R2.fq"
    output:
        "transrate/{sample}_TIMESTAMP.transrate/{sample}_TIMESTAMP.Trinity/good.{sample}_TIMESTAMP.Trinity.fasta",
        "transrate/{sample}_TIMESTAMP.transrate/assemblies.csv",
        "transrate/{sample}_TIMESTAMP.transrate/{sample}_TIMESTAMP.Trinity/contigs.csv"
    log:
    	"logs/transrate/{sample}_TIMESTAMP.log"
    params:
        transDir  =  config["transrateDir"],
        dataDir   =  config["fastqdir"],
        homeDir   =  config["homedir"],
        transrate =  config["transrate"]
    threads: 28
    shell:
        """
        {params.transrate} --assembly {params.homeDir}{input.assembly} \
        --output {params.transDir}{wildcards.sample}.transrate \
        --threads {threads} \
        --left {input.forward} \
        --right {input.reverse} > logs/transrate/{wildcards.sample}.transrate.log 2> {log}
        """


rule gather_transrate:
    # move all transrate results to same folder for easier summary later
    # First I used the same wildcard input output names for this rule as I did
    # for the gather busco rule but that somehow caused it not to be plotted in the
    # dag. More of a cosmetic issue.
    input:
        a = "transrate/{sample}_TIMESTAMP.transrate/assemblies.csv",
        c  = "transrate/{sample}_TIMESTAMP.transrate/{sample}_TIMESTAMP.Trinity/contigs.csv"
    output:
        a = "transrate/summary/{sample}_TIMESTAMP.assemblies.csv",
        c = "transrate/summary/{sample}_TIMESTAMP.contigs.csv"
    shell:
        """
        cp {input.a} {output.a}
        cp {input.c}  {output.c}

        """


rule summarize_transrate_assembly:
    input:
        expand("transrate/summary/{sample}_TIMESTAMP.assemblies.csv",sample=SAMPLES)
    output:
        "transrate/summary/run_" + TIMESTAMP + "_assemblies.csv"
    run:
        assemblies = input
        #generate first line we need in outfile:
        with open(output[0], "w") as outfile:
            with open(assemblies[0], "r") as infile:
                lines = infile.readlines()
                outfile.write(lines[0])

        # now we open the outfile in appending mode to add all the results
        with open(output[0], "a") as outfile:
            for assembly in assemblies:
                with open(assembly, "r") as infile:
                    lines = infile.readlines()
                    outfile.write(lines[1])


# transrate plotting
# TODO change locations of file to something sensible
# ownimgg directory?
rule plot_transrate_contigs:
    input:
        "transrate/summary/{sample}_TIMESTAMP.contigs.csv"
    output:
        "{sample}_TIMESTAMP.png"
    params:
        TIMESTAMP
    script:
        "R/contigs.plot.R"


# add busco rule
rule busco:
    input:
        assembly =   "{sample}_TIMESTAMP.Trinity.fasta"
    output:
        out      =   config["homedir"] + "busco/run_{sample}_TIMESTAMP.busco/short_summary_{sample}_TIMESTAMP.busco.txt"
    params:
        py3      =   config["py3"],
        BUSCO    =   config["BUSCO"],
        BuscoLib =   config["BuscoLib"],
        homedir  =   config["homedir"],
        folder   =   "run_{sample}_TIMESTAMP.busco"
    threads: 14
    log:
        "logs/busco/{sample}_TIMESTAMP.log"

    shell:
        # cd {params.outdir}
        """
        {params.py3}  {params.BUSCO} -f \
                -i {params.homedir}{input.assembly} \
                -o {wildcards.sample}.busco              \
                -l  {params.BuscoLib}    \
                -m  tran -c {threads} &>> {log} && \
        mv  {params.folder}  busco/

        """


rule busco_on_transrate:
    # run busco on transrate optimized assembly
    input:
        assembly =   "transrate/{sample}_TIMESTAMP.transrate/{sample}_TIMESTAMP.Trinity/good.{sample}_TIMESTAMP.Trinity.fasta"
    output:
        out      =   config["homedir"] + "busco/run_{sample}_TIMESTAMP.good.busco/short_summary_{sample}_TIMESTAMP.good.busco.txt"
    params:
        outdir   =   config["homedir"] + "busco/",
        py3      =   config["py3"],
        BUSCO    =   config["BUSCO"],
        BuscoLib =   config["BuscoLib"],
        homedir  =   config["homedir"],
        folder   =   "run_{sample}_TIMESTAMP.good.busco"
    threads: 14
    log:
        "logs/busco/{sample}_TIMESTAMP.good.log"
    shell:
        # cd {params.outdir}
        """
        {params.py3}  {params.BUSCO} -f \
                -i {params.homedir}{input.assembly} \
                -o {wildcards.sample}.good.busco              \
                -l  {params.BuscoLib}    \
                -m  tran -c {threads} &>> {log} && \
        mv  {params.folder}  busco/

        """


# TODO rule decision on assembly
rule gather_busco:
    # move all transrate results to same folder for easier summary later
    # we do not need the expand statement here because plot busco will just call this function many times
    input:
        normal   = config["homedir"] + "busco/run_{sample}_TIMESTAMP.busco/short_summary_{sample}_TIMESTAMP.busco.txt",
        good     = config["homedir"] + "busco/run_{sample}_TIMESTAMP.good.busco/short_summary_{sample}_TIMESTAMP.good.busco.txt"
    output:
        normal   = "busco/summary/short_summary_{sample}_TIMESTAMP.busco.txt",
        good     = "busco/summary/short_summary_{sample}_TIMESTAMP.good.busco.txt"
    shell:
        """
        cp {input.normal} {output.normal}
        cp {input.good}   {output.good}

        """


rule plot_busco:
    input:
        normal   = expand("busco/summary/short_summary_{sample}_TIMESTAMP.busco.txt", sample=SAMPLES),
        good     = expand("busco/summary/short_summary_{sample}_TIMESTAMP.good.busco.txt", sample=SAMPLES)
    output:
        png      = "busco/summary/run_" + TIMESTAMP + "_busco.png",
        R        = "busco/summary/run_" + TIMESTAMP + "_busco.R"
    params:
        py3      = config["py3"],
        BUSCO_p  = config["BUSCO_p"]
    shell:
        """
        {params.py3} {params.BUSCO_p} --working_directory busco/summary && \
        mv busco/summary/busco_figure.png {output.png} && \
        mv busco/summary/busco_figure.R {output.R}
        """


# TODO rename assembly headers
# TODO
# add plotting for BUSCO
# The default plotting does not work and we have to add
# options(bitmapType='cairo')
# at the beginning of the script. -.-
rule versions:
    output:
        log         = "logs/software.versions"
    params:
        trinity     = config["trinity"],
        transrate   = config["transrate"],
        BUSCO       = config["BUSCO"],
        time        = TIMESTAMP
    shell:
        """
        echo "These are the versions of software used for run: {params.time}" &>> {output.log}
        date  &>> {output.log}
        python --version &>> {output.log}
        hmmscan -h | grep -E '^\#\ H' &>> {output.log}
        blastn -h | grep Nucleotide &>> {output.log}
        embossversion &>> {output.log}
        echo "perl version: " &>> {output.log}
        perl -e 'print $];' &>> {output.log}
        {params.BUSCO} --version &>> {output.log}
        echo "transrate version:" {params.transrate} --version &>> {output.log}
        {params.trinity} --version &>> {output.log}
        """
# TODO report file should contain:
# plot of coverage
# busco and transrate stats
# software versions
# timestamp


rule report:
    input:
        busco_png           = "busco/summary/run_" + TIMESTAMP + "_busco.png",
        transrate_summary   = "transrate/summary/run_" + TIMESTAMP + "_assemblies.csv",
        assembly_plot       = expand("{sample}_TIMESTAMP.png", sample=SAMPLES),
        versions            = "logs/software.versions"
    output:
        "report.html"
    run:
        # from snakemake.utils import report
        #with open(input[0]) as trans.logs:
        #    print(trans.logs)
        report("""
        Report on macpipe_trans run
        ==================================
        .. image:: {input.busco_png}
        assembly_plot_
        """, output[0], **input)


# Finishing up --------------------------------------------------------------
onsuccess:
    print("Workflow finished, no error")
onerror:
    print("An error occurred with the snakemake run")
    # here it would be good to include timstamping
    shell("mail -s 'Error in Snakemake run' jeremias.brand@unibas.ch < {log}")
# TODO add separate snakefile for annotation
